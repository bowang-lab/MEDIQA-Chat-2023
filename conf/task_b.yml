# ModelArguments
model_name_or_path: "patrickvonplaten/led-large-16384-pubmed"

# DataTrainingArguments
text_column: "dialogue"
summary_column: "note"
train_file: "./datasets/MEDIQA-Chat-Training-ValidationSets-Feb-10-2023/TaskB/TaskB-TrainingSet.csv"
validation_file: "./datasets/MEDIQA-Chat-Training-ValidationSets-Feb-10-2023/TaskB/TaskB-ValidationSet.csv"
test_file: "./datasets/MEDIQA-Chat-Training-ValidationSets-Feb-10-2023/TaskB/TaskB-ValidationSet.csv"
max_source_length: 4096
# This is the maximum length of the target sequences for training. You can save compute during training with little
# impact on performance by setting this to a lower value, e.g. the 95th percentile of the observed lengths.
max_target_length: 1024
generation_max_length: 1024
# This is the maximum length of the target sequence for evaluation (during training and after training
# respectively). It should be set to the maximum observed length in the validation set (or as large as the model
# supports, whichever is smaller) so we get an accurate evaluation.
val_max_target_length: 1024
source_prefix: "Summarize the following patient-doctor dialogue. Include all medically relevant information, including family history, diagnosis, past medical (and surgical) history, immunizations, lab results and known allergies. Dialogue:"
# Specify which challenge task to run, which changes some of the pre and post processing
task: "B"

# Seq2SeqTrainingArguments
# See: https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments
do_train: true
do_eval: true
do_predict: true
per_device_train_batch_size: 1
per_device_eval_batch_size: 6
gradient_accumulation_steps: 8
learning_rate: 3e-5
weight_decay: 0.01
num_train_epochs: 50
warmup_ratio: 0.1
label_smoothing_factor: 0.1
fp16: true
num_beams: 4
generation_num_beams: 4
# Controls the evaluation strategy
evaluation_strategy: "steps"
eval_steps: 100
eval_delay: 100
# Controls the checkpointing strategy
save_strategy: "steps"
save_steps: 100
save_total_limit: 1
load_best_model_at_end: true
metric_for_best_model: "ensemble_gen_score"