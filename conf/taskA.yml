# ModelArguments
model_name_or_path: "google/flan-t5-large"

# DataTrainingArguments
text_column: "dialogue"
summary_column: "section_text"
train_file: "./datasets/MEDIQA-Chat-Training-ValidationSets-Feb-10-2023/TaskA/TaskA-TrainingSet.csv"
validation_file: "./datasets/MEDIQA-Chat-Training-ValidationSets-Feb-10-2023/TaskA/TaskA-ValidationSet.csv"
test_file: "./datasets/MEDIQA-Chat-Training-ValidationSets-Feb-10-2023/TaskA/TaskA-ValidationSet.csv"
max_source_length: 1024
# This is the maximum length of the target sequences for training. You can save compute during training with little
# impact on performance by setting this to a lower value, e.g. the 95th percentile of the observed lengths.
max_target_length: 512
generation_max_length: 512
# This is the maximum length of the target sequence for evaluation (during training and after training
# respectively). It should be set to the maximum observed length in the validation set (or as large as the model
# supports, whichever is smaller) so we get an accurate evaluation.
val_max_target_length: 512
source_prefix: "Summarize the following patient-doctor dialogue. Include all medically relevant information, including family history, diagnosis, past medical (and surgical) history, immunizations, lab results and known allergies. You should first predict the most relevant clinical note section header and then summarize the dialogue. Dialogue:"
task: "A"

# Seq2SeqTrainingArguments
# See: https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments
do_train: true
do_eval: true
do_predict: true
per_device_train_batch_size: 2
per_device_eval_batch_size: 12
gradient_accumulation_steps: 4
learning_rate: 1e-4
weight_decay: 0.01
num_train_epochs: 20
warmup_ratio: 0.1
label_smoothing_factor: 0.1
bf16: true
num_beams: 2
generation_num_beams: 2
# Controls the evaluation strategy
evaluation_strategy: "steps"
logging_steps: 200
eval_delay: 1000
# Controls the checkpointing strategy
save_strategy: "steps"
save_steps: 200
save_total_limit: 1
load_best_model_at_end: true
metric_for_best_model: "ensemble_score"